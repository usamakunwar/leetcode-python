{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 126. Word Ladder II (Hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><p>Given two words (<em>beginWord</em> and <em>endWord</em>), and a dictionary's word list, find all shortest transformation sequence(s) from <em>beginWord</em> to <em>endWord</em>, such that:</p>\n",
    "\n",
    "<ol>\n",
    "\t<li>Only one letter can be changed at a time</li>\n",
    "\t<li>Each transformed word must exist in the word list. Note that <em>beginWord</em> is <em>not</em> a transformed word.</li>\n",
    "</ol>\n",
    "\n",
    "<p><strong>Note:</strong></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Return an empty list if there is no such transformation sequence.</li>\n",
    "\t<li>All words have the same length.</li>\n",
    "\t<li>All words contain only lowercase alphabetic characters.</li>\n",
    "\t<li>You may assume no duplicates in the word list.</li>\n",
    "\t<li>You may assume <em>beginWord</em> and <em>endWord</em> are non-empty and are not the same.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Example 1:</strong></p>\n",
    "\n",
    "<pre><strong>Input:</strong>\n",
    "beginWord = \"hit\",\n",
    "endWord = \"cog\",\n",
    "wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n",
    "\n",
    "<strong>Output:</strong>\n",
    "[\n",
    "  [\"hit\",\"hot\",\"dot\",\"dog\",\"cog\"],\n",
    "&nbsp; [\"hit\",\"hot\",\"lot\",\"log\",\"cog\"]\n",
    "]\n",
    "</pre>\n",
    "\n",
    "<p><strong>Example 2:</strong></p>\n",
    "\n",
    "<pre><strong>Input:</strong>\n",
    "beginWord = \"hit\"\n",
    "endWord = \"cog\"\n",
    "wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\"]\n",
    "\n",
    "<strong>Output: </strong>[]\n",
    "\n",
    "<strong>Explanation:</strong>&nbsp;The endWord \"cog\" is not in wordList, therefore no possible<strong>&nbsp;</strong>transformation.\n",
    "</pre>\n",
    "\n",
    "<ul>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1\n",
    "<p>\n",
    "    BFS\n",
    "    <p>\n",
    "        <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "class Solution(object):\n",
    "    def findLadders(self, beginWord, endWord, wordList):\n",
    "        ln = len(beginWord)\n",
    "        m = collections.defaultdict(list)\n",
    "        \n",
    "        for w in wordList:\n",
    "            for i in range(ln):\n",
    "                m[w[:i]+'*'+w[i+1:]].append(w)\n",
    "                \n",
    "        seen = set()\n",
    "        res = []\n",
    "        q = collections.deque([[beginWord]])\n",
    "        while q:\n",
    "            curr = q.popleft()\n",
    "            #We need to allow duplicate elements to be queued multiple times, \n",
    "            #as many paths can then lead to the same path\n",
    "            seen.add(curr[-1])\n",
    "            if res and len(curr) > len(res[-1]): break  #We are using len(curr) as a depth check\n",
    "            if curr[-1] == endWord: res.append(curr) \n",
    "            if res: continue\n",
    "            for i in range(ln):\n",
    "                for w in m[curr[-1][:i]+'*'+curr[-1][i+1:]]: \n",
    "                    if w in seen: continue\n",
    "                    q.append(curr+[w])\n",
    "            \n",
    "        return res\n",
    "\n",
    "Solution().findLadders(\"hit\", \"cog\", [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result: 1296ms (14.85%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
